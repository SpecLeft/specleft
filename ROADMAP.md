# SpecLeft Roadmap

## Current (v0.4.0 - Foundation)
- âœ… Spec-defined test decoration
- âœ… Step-by-step test tracing
- âœ… Skeleton test generation from JSON specs
- âœ… Basic HTML test reporting
- âœ… Pytest plugin integration
- ğŸªœ **Add Features and Scenarios Command** â€” Incrementally add features and scenarios via the CLI for quick enhancement of a plan
- ğŸ”– **Enhanced PRD parsing** - More flexible converting of prd.md in to feature units.
- ğŸ“œ **Logged Feature Changes** - Keep a historical trace of features and scenarios added to the project. Provides externalised memory to agents
- ğŸ“– **Agent Guide** - Provide clarity and guidance for agents to know how to best proceed in scenarios such as: refactoring, cleanup, regression bugs, features and scenarios.
- ğŸ”„ **Async test handling** - Async tests are now supported with @specleft decorator and step context manager
- ğŸ§ª **Test Stubs** - Create empty test containers as an alternate to test skeletons.
- ğŸ‘¾ **MCP Server** - A SpecLeft MCP server to smoother integration with AI agents.
- âœï¸Â **Agent Skills**Â - Integrated agent skills for more autonomous planning and test generation.


## Future (v0.5.0 and beyond)
- ğŸšï¸Â **SpecLeft CLI Filters**Â â€” First-class test selection viaÂ `--specleft-tag/priority/feature/scenario`Â flags and pytest config defaults.
- ğŸ¤–Â **AI-Generated Tests**Â â€” Let SpecLeft generate test implementations from your feature specs using LLMs. SpecLeft provides richer context and understanding for more robust behaviour testing capability. Reduce boilerplate even further.

## Community & Contributions

Have ideas? Found a use case we should support? Open an issue or start a discussion â€” it'd be great to hear from you!
