"""
Acceptance tests for Feature 1: Planning Mode.

These tests verify the end-to-end behaviour of `specleft plan`
using Click's CliRunner to replicate real user flows.

Generated by SpecLeft - https://github.com/SpecLeft/specleft
"""

from __future__ import annotations

import shutil
from pathlib import Path

from click.testing import CliRunner
import click
import pytest

from specleft import specleft
from specleft.templates.prd_template import load_template
from specleft.cli.main import cli
from conftest import PrdFiles

# =============================================================================
# Feature: Feature 1: Planning Mode
# ID: feature-1-planning-mode
# priority: critical
# =============================================================================


@specleft(
    feature_id="feature-1-planning-mode",
    scenario_id="generate-feature-files-from-prd",
)
def test_generate_feature_files_from_prd(
    feature_1_prd_multi_feature: tuple[CliRunner, Path, PrdFiles],
) -> None:
    """Generate feature files from PRD

    Priority: critical

    Verifies that `specleft plan` creates feature files from a PRD,
    each feature maps to a user-visible capability, and no code or
    test files are modified.
    """
    runner, workspace, _prd_files = feature_1_prd_multi_feature

    with specleft.step("Given a repository contains a prd.md"):
        # PRD is already created by fixture
        # Create a dummy src/ and tests/ to verify they are not modified
        Path("src").mkdir()
        Path("src/app.py").write_text("# Application code\n")
        Path("tests").mkdir()
        Path("tests/test_app.py").write_text("# Test code\n")

        # Record original content for later comparison
        original_src = Path("src/app.py").read_text()
        original_test = Path("tests/test_app.py").read_text()

    with specleft.step("When specleft plan is executed"):
        result = runner.invoke(cli, ["plan"])

    with specleft.step("Then feature files are created under features/"):
        assert result.exit_code == 0, f"Command failed: {result.output}"
        assert Path("features").exists(), "features/ directory not created"
        assert Path("features").is_dir(), "features/ is not a directory"

        # Should have created feature files
        feature_files = list(Path("features").glob("*.md"))
        assert (
            len(feature_files) >= 2
        ), f"Expected at least 2 feature files, got {len(feature_files)}"

    with specleft.step("And each feature maps to a user-visible capability"):
        # Check that feature files correspond to PRD headings
        auth_feature = Path("features/feature-1-user-authentication.md")
        payment_feature = Path("features/feature-2-payment-processing.md")

        assert auth_feature.exists(), f"Expected {auth_feature} to exist"
        assert payment_feature.exists(), f"Expected {payment_feature} to exist"

        # Verify content structure - should contain Feature title
        auth_content = auth_feature.read_text()
        assert "# Feature 1:" in auth_content, "Feature file missing Feature header"
        assert (
            "Authentication" in auth_content or "authentication" in auth_content.lower()
        )

        payment_content = payment_feature.read_text()
        assert "# Feature 2:" in payment_content, "Feature file missing Feature header"
        assert "Payment" in payment_content or "payment" in payment_content.lower()

    with specleft.step("And no code or test files are modified"):
        # Verify that source and test files remain unchanged
        assert Path("src/app.py").read_text() == original_src, "src/app.py was modified"
        assert (
            Path("tests/test_app.py").read_text() == original_test
        ), "tests/test_app.py was modified"


@specleft(
    feature_id="feature-1-planning-mode",
    scenario_id="derive-feature-filenames-from-prd-headings",
)
def test_derive_feature_filenames_from_prd_headings(
    feature_1_prd_slug_test: tuple[CliRunner, Path, PrdFiles],
) -> None:
    """Derive feature filenames from PRD headings

    Priority: critical

    Verifies that filenames are derived as slugs from feature titles
    and existing feature files are not overwritten.
    """
    runner, _workspace, _prd_files = feature_1_prd_slug_test

    # Store the existing content for later verification
    existing_content = "# Feature: User Authentication & Login\n\nCustom content that should NOT be overwritten.\n"

    with specleft.step("Given the PRD contains multiple feature sections"):
        # PRD and pre-existing feature file are already created by fixture
        pass

    with specleft.step("When feature files are generated"):
        result = runner.invoke(cli, ["plan"])
        assert result.exit_code == 0, f"Command failed: {result.output}"

    with specleft.step("Then filenames are derived as slugs from feature titles"):
        # Slugs should be lowercase, hyphenated, without special characters
        # "User Authentication & Login" -> "feature-user-authentication-login"
        # "Data Export (CSV/JSON)" -> "feature-data-export-csv-json"
        auth_file = Path("features/feature-user-authentication-login.md")
        export_file = Path("features/feature-data-export-csv-json.md")

        # At minimum, the export file should be created (auth was pre-existing)
        assert export_file.exists(), f"Expected {export_file} to be created as slug"

        # Verify slug naming - no uppercase, no special chars
        for feature_file in Path("features").glob("*.md"):
            filename = feature_file.stem
            assert (
                filename == filename.lower()
            ), f"Filename {filename} should be lowercase"
            # Slugs should not contain characters like &, (, ), /
            assert "&" not in filename, f"Filename {filename} contains '&'"
            assert "(" not in filename, f"Filename {filename} contains '('"
            assert ")" not in filename, f"Filename {filename} contains ')'"

    with specleft.step("And existing feature files are not overwritten"):
        # The pre-existing file should retain its original content
        auth_file = Path("features/feature-user-authentication-login.md")
        current_content = auth_file.read_text()
        assert current_content == existing_content, (
            "Existing feature file was overwritten.\n"
            f"Expected: {existing_content!r}\n"
            f"Got: {current_content!r}"
        )

        # Output should indicate the file was skipped
        assert (
            "Skipped" in result.output or "skipped" in result.output.lower()
        ), "Expected indication that existing file was skipped"


@specleft(
    feature_id="feature-1-planning-mode",
    scenario_id="handle-missing-prd-gracefully",
)
def test_handle_missing_prd_gracefully(acceptance_workspace) -> None:
    """Handle missing PRD gracefully

    Priority: medium

    Verifies that when no PRD file exists, a clear warning is emitted
    and no feature files are created.
    """
    runner, _workspace = acceptance_workspace

    with specleft.step("Given no PRD file exists in the repository"):
        # Remove the features/ directory created by the fixture
        # (this test verifies features/ is NOT created when PRD is missing)
        if Path("features").exists():
            shutil.rmtree("features")

        # Ensure no prd.md exists in the isolated filesystem
        assert not Path("prd.md").exists(), "prd.md should not exist"
        assert not Path("docs/prd.md").exists(), "docs/prd.md should not exist"

    with specleft.step("When specleft plan is executed"):
        result = runner.invoke(cli, ["plan"])

    with specleft.step("Then a clear warning is emitted"):
        # Command should complete (exit 0) but with warning
        assert (
            result.exit_code == 0
        ), f"Command should succeed with warning, got exit code {result.exit_code}"

        # Should contain clear warning about missing PRD
        output_lower = result.output.lower()
        assert "prd" in output_lower and (
            "not found" in output_lower or "warning" in output_lower
        ), f"Expected warning about missing PRD in output:\n{result.output}"

        # Should suggest expected locations
        assert (
            "expected" in output_lower or "location" in output_lower
        ), f"Expected suggestion of PRD locations in output:\n{result.output}"

    with specleft.step("And no feature files are created"):
        # features/ directory should not be created
        assert not Path(
            "features"
        ).exists(), "features/ directory should not be created when PRD is missing"


@specleft(
    feature_id="feature-1-planning-mode",
    scenario_id="trace-async-test-execution",
)
async def test_trace_async_test_execution() -> None:
    """Trace async test execution

    Priority: high

    Verifies that @specleft decorator works correctly with pytest-asyncio tests,
    properly awaiting async functions and recording step results.
    """
    import asyncio

    from specleft.decorators import async_step, get_current_steps, is_in_specleft_test

    with specleft.step(
        "Given a test function decorated with @specleft and @pytest.mark.asyncio"
    ):
        # This test itself is the async test - we're verifying it runs correctly
        assert is_in_specleft_test(), "Should be inside a specleft test"

    async with async_step("When the async test is executed with pytest"):
        # Simulate some async work
        await asyncio.sleep(0.01)
        result = "async_completed"

    with specleft.step("Then the test runs successfully"):
        assert result == "async_completed", "Async operation should complete"

    with specleft.step("And step results are properly recorded"):
        steps = get_current_steps()
        # We should have 4 steps at this point (this is the 4th)
        assert len(steps) >= 3, f"Expected at least 3 steps, got {len(steps)}"

        # Verify async step was recorded
        step_descriptions = [s.description for s in steps]
        assert any(
            "async test is executed" in desc for desc in step_descriptions
        ), f"Async step not found in {step_descriptions}"

    with specleft.step("And the async function is awaited correctly"):
        # If we got here, the async function was awaited correctly
        # (otherwise we'd have a coroutine object, not a result)
        assert is_in_specleft_test(), "Context should still be active"


@specleft(
    feature_id="feature-1-planning-mode",
    scenario_id="validate-prd-template-definitions",
)
def test_validate_prd_template_definitions(tmp_path: Path) -> None:
    """Validate PRD template definitions

    Priority: high

    Verifies invalid heading levels and invalid patterns are rejected
    with clear errors when loading PRD templates.
    """
    invalid_heading = tmp_path / "invalid-heading.yml"
    invalid_heading.write_text("""
version: "1.0"
features:
  heading_level: 0
""".lstrip())

    invalid_pattern = tmp_path / "invalid-pattern.yml"
    invalid_pattern.write_text("""
version: "1.0"
features:
  heading_level: 2
  patterns:
    - "Feature: {title"
""".lstrip())

    with specleft.step("Given a PRD template file defines headings and patterns"):
        assert invalid_heading.exists()
        assert invalid_pattern.exists()

    with specleft.step("When the template is loaded for planning"):
        with pytest.raises(click.ClickException):
            load_template(invalid_heading)
        with pytest.raises(click.ClickException):
            load_template(invalid_pattern)

    with specleft.step("Then invalid heading levels are rejected with a clear error"):
        with pytest.raises(click.ClickException) as excinfo:
            load_template(invalid_heading)
        assert "heading" in str(excinfo.value).lower()

    with specleft.step("And invalid patterns are rejected with a clear error"):
        with pytest.raises(click.ClickException) as excinfo:
            load_template(invalid_pattern)
        assert "pattern" in str(excinfo.value).lower()


@specleft(
    feature_id="feature-1-planning-mode",
    scenario_id="analyze-prd-structure-without-writing-files",
)
def test_analyze_prd_structure_without_writing_files() -> None:
    """Analyze PRD structure without writing files

    Priority: high

    Verifies that analyze mode classifies headings and does not create files.
    """
    runner = CliRunner()
    with runner.isolated_filesystem():
        Path("prd.md").write_text(
            "# PRD\n\n## Overview\n\n## Feature: Billing\n\n## Notes\n\n## Payments\n"
        )

        with specleft.step("Given a PRD contains headings that mix features and notes"):
            assert Path("prd.md").exists()

        with specleft.step("When specleft plan --analyze is executed"):
            result = runner.invoke(cli, ["plan", "--analyze"])

        with specleft.step(
            "Then the output classifies headings as feature, excluded, or ambiguous"
        ):
            assert result.exit_code == 0, f"Command failed: {result.output}"
            output = result.output
            assert "Analyzing PRD structure" in output
            assert "Features:" in output
            assert "Excluded:" in output
            assert "Ambiguous:" in output

        with specleft.step("And no feature files are created"):
            assert not Path("features").exists()


@specleft(
    feature_id="feature-1-planning-mode",
    scenario_id="generate-features-with-a-custom-prd-template",
)
def test_generate_features_with_custom_prd_template() -> None:
    """Generate features with a custom PRD template

    Priority: high

    Verifies that custom template patterns drive feature/scenario extraction.
    """
    runner = CliRunner()
    with runner.isolated_filesystem():
        Path("prd.md").write_text(
            "# PRD\n\n## Epic: Billing\n\n### AC: Refund requested\n- Priority = p0\n"
        )
        Path("template.yml").write_text("""
version: "1.0"

features:
  heading_level: 2
  patterns:
    - "Epic: {title}"
  contains: []
  match_mode: "any"

scenarios:
  heading_level: [3]
  patterns:
    - "AC: {title}"
  contains: []
  match_mode: "any"

priorities:
  patterns:
    - "Priority = {value}"
  mapping:
    p0: critical
""".lstrip())

        with specleft.step(
            "Given a PRD template defines custom feature and scenario patterns"
        ):
            assert Path("template.yml").exists()

        with specleft.step("When specleft plan --template <file.yml> is executed"):
            result = runner.invoke(cli, ["plan", "--template", "template.yml"])

        with specleft.step("Then features are generated using the custom patterns"):
            assert result.exit_code == 0, f"Command failed: {result.output}"
            feature_file = Path("features/epic-billing.md")
            assert feature_file.exists()

        with specleft.step("And priorities are normalized using the template mapping"):
            content = feature_file.read_text()
            assert "priority: critical" in content
